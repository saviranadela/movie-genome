---
title: "Assignment 4"
author: "Savira Dwia Nadela"
format:
  html:
    toc: true
    toc-expand: 2
    toc-location: left
editor: visual
---

# Instructions

-   Use a Google doc to submit your answers and write directly in that document (i.e., don't write your answers in Rstudio and copy paste them to your google doc). Your code does not have to be in the Google doc. Please submit this qmd file on Canvas and add the link to your Google doc as a comment to your submission.

-   This is an individual assignment. You are allowed to *ask advice from* peers and use generative AI, but the end product must be *individual work* that is written in your own words and distinct from work submitted by peers or generated by AI. This assignment is subject to the [**Stanford Student Honor Code.**](https://communitystandards.stanford.edu/policies-and-guidance/honor-code)

**I worked with: GenAI**

# Short Questions

### Q1

**Consider the figure below. This is the first iteration of a Gaussian Mixture Model and has the following two mean values. Describe what you expect to happen to these means in the next iteration and how that will happen in your own words.**

![](means.png){width="251"}

### **Q2**

**Here is a dendogram that shows the results of hierarchical clustering using single linkage with Euclidean distance.** **How many clusters will you get if you cut the dendogram at height = 2, at height = 1, and at height = 0.5?**

![](dendogram.png)

### Q3

**Explain in your own words how k-means clustering, hierarchical clustering, and Gaussian mixture models differ from each other.**

# Data

For this assignment, we will be examining movies using the Movie Genome Dataset which includes movies and tags that reflect how much a particular tag applies to a movie. It is a not about education and a little silly, but I figure we can have some fun for the last problem set. The main goal is to reduce both columns and rows and answer the question: **What types of movies have people tagged?**

You will work with the Movie Genome Dataset, which has been developed by the MovieLens project.

From their read.me:

*The Tag Genome dataset contains movie-tag pair scores which indicate the degrees to which tags apply to movies. This dataset was introduced in \[Vig et al., 2012\]. To generate the dataset, the authors collected the following information about movies: metadata (title, directors, actors...), movie reviews from IMDB (<https://imdb.com/),> ratings, tags that users attached to movies in MovieLens (<https://movielens.org/)> and user judgements regarding the degrees to which tags apply to movies. The authors collected user judgements with a survey in MovieLens and used these data to train and evaluate their algorithm. The algorithm is based on regression and predicts the movie-tag scores. The authors of \[Kotkov et al., 2021\] prepared the raw movie data for publication, refactored the programming code of the algorithm and introduced TagDL, a novel algorithm for prediction of movie-tag scores. TagDL is based on neural networks and uses the same features as the regression algorithm of \[Vig et al., 2012\]. The code is available in the GitHub repository via the following link: <https://github.com/Bionic1251/Revisiting-the-Tag-Relevance-Prediction-Problem>*

The complete dataset contains 84,661 movies and 1,087 tags. It takes a long time to run the PCA on this dataset, so **work with random sample first** until you feel confident that you have set everything up correctly (don't spend a lot of time interpreting the PCA

Add libraries

```{r}
library(tidyverse)
library(tidytext)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(mclust)
library(ggrepel)
```

Let's read the data

```{r}
movies <- read_csv("assignment 4 movies.csv")
```

# PCA

### **Q4**

**Run a PCA model on all the character traits. Look in the help file (`?PCA`) how you can make sure the function will return the results of at least 15 dimensions. Produce:**

-   **a scree plot**

-   **a plot of the cumulative explained variance**

**Interpret both plots and decide how many dimensions/components you will retain. Argue for your decision.**

```{r pca}
cat_data <- movies %>% select(-item_id, -title, -avgRating)

pca_result <- PCA(cat_data, scale.unit = TRUE, ncp = 15, graph = FALSE)

summary(pca_result)
```

```{r screeplot}
fviz_eig(pca_result, addlabels = TRUE, choice = "variance", barfill = "steelblue")
```

```{r explained-variances}

cumulative_var <- pca_result$eig[, 3]

pca_df <- data.frame(
  Component = 1:length(cumulative_var),
  CumulativeVariance = cumulative_var
)

library(ggplot2)
ggplot(pca_df, aes(x = Component, y = CumulativeVariance)) +
  geom_point(color = "darkred") +
  geom_line(color = "darkred") +
  labs(title = "Cumulative Explained Variance",
       x = "Number of Principal Components",
       y = "Cumulative Variance Explained (%)") +
  theme_minimal()


```

```{r}
ggplot(pca_df, aes(x = Component, y = CumulativeVariance)) +
  geom_point(color = "darkred", size = 1) +
  geom_line(color = "darkred") +
  labs(
    title = "Cumulative Explained Variance",
    x = "Number of Principal Components",
    y = "Cumulative Variance Explained (%)"
  ) +
  theme_minimal() +
  xlim(0, 300) 
```

### **Q5**

**Extract the PCA loadings of 15 principal components (even if you decided to retain fewer or more) and plot the top 10 most contributing variables to the principal component in a bar graph. This is actually quite some work, so I have added an example with the lab data in the assignment folder called "example pset4.html.**

```{r}
var <- get_pca_var(pca_result)

pca_loadings <- t(var$coord) |> 
  as_tibble(rownames = "dimension") |> 
  pivot_longer(cols = -dimension, 
               names_to = "variable", 
               values_to = "loading") |> 
  mutate(importance = loading^2,
         dimension = as.factor(dimension))

top10_vars <- pca_loadings |> 
  group_by(dimension) |> 
  slice_max(order_by = importance, n = 10)

ggplot(top10_vars, aes(x = reorder(variable, importance), y = importance, fill = dimension)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~dimension, scales = "free_y") +
  labs(title = "Top 10 Contributing Variables per Principal Component",
       x = "Variable",
       y = "Contribution (Importance)") +
  theme_minimal()

```

### **Q6**

**Interpret and label the 15 principal components.**

# Clustering

**We will now run k means clustering *on the PCA solution*. For that, you need to add the dimensions from the PCA to the dataset. We will add 15 dimensions to the data (irrespective of whether you choose a different number of dimensions to retain earlier).**

### **Q7**

**Run a Gaussian Mixture Model and let the model decide on the best type of model and number of clusters. What model did mclust decide on and how many clusters did mclust end up with?**

```{r gmm}

pca_data <- as.data.frame(pca_result$ind$coord[, 1:15])
gmm_model <- Mclust(pca_data)
summary(gmm_model)
plot(gmm_model, what = "classification")
```

```{r}
cat("Best model selected by Mclust:", gmm_model$modelName, "\n")
cat("Number of clusters:", gmm_model$G, "\n")
```

### Q8

**Do you think that a k-means clustering algorithm would have arrived at a similar classification? Why or why not?**

### Q9

**Think of at least 10 movies you know well. Add the classification of the GMM to your data. Plot the titles of these movies on the first two principal components from the PCA, and color the characters by their cluster membership.Hint: use `geom_point()` and `geom_label_repel()` to see the names of fictional characters in your plot of principal components and cluster membership.**

```{r plot-10-movies}
movies_pca_df <- as.data.frame(pca_result$ind$coord[, 1:15])
movies_pca_df$Cluster <- as.factor(gmm_model$classification)
movies_pca_df$Title <- movies$title
```

```{r}
selected_movies <- c("Toy Story (1995)", "Saving Private Ryan (1998)", "Forrest Gump (1994)", "Shawshank Redemption, The (1994)", "Breakfast Club, The (1985)", "Pursuit of Happyness, The (2006)", "Green Book (2018)", "Spirited Away (Sen to Chihiro no kamikakushi) (2001)", "Coco (2017)", "The Imitation Game (2014)", "Eternal Sunshine of the Spotless Mind (2004)")

movies_subset <- movies_pca_df %>% filter(Title %in% selected_movies)
```

```{r}
ggplot(movies_pca_df, aes(x = Dim.1, y = Dim.2, color = Cluster)) +
  geom_point(alpha = 0.5) +
  geom_point(data = movies_subset, aes(x = Dim.1, y = Dim.2), color = "black", size = 3) +
  geom_label_repel(data = movies_subset, aes(label = Title), size = 4, box.padding = 0.5) +
  labs(title = "Movies Plotted on First Two Principal Components",
       x = "PC1",
       y = "PC2",
       color = "Cluster") +
  theme_minimal()
```

### Q10

**How confident are you about the hard classifications that the Gaussian Model returned by asssessing the solution for your five fictional works?**

# Reflection

**The following questions are not part of your grade.**

**How was this assignment for you?**

**Do you have any questions you'd like to discuss in class?**
